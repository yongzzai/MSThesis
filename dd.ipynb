{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca6690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size: 32, \n",
      "Sequence Length: 20\n",
      "Hidden: 256\n",
      "\n",
      "GRU----------------------\n",
      "입력 차원: torch.Size([32, 20, 100])\n",
      "출력 차원: torch.Size([32, 20, 256])\n",
      "은닉 상태 차원: torch.Size([4, 32, 256])\n",
      "마지막 은닉 상태 차원: torch.Size([32, 256])\n",
      "\n",
      "Bi-GRU-------------------\n",
      "입력 차원: torch.Size([32, 20, 100])\n",
      "출력 차원: torch.Size([32, 20, 512])\n",
      "은닉 상태 차원: torch.Size([8, 32, 256])\n",
      "마지막 은닉 상태 차원: torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Bi-GRU 모델 정의\n",
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=4):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.bigru = nn.GRU(input_size, hidden_size, num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output, hidden = self.bigru(x)\n",
    "        return output, hidden\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=4):\n",
    "        super(GRU, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, \n",
    "                          batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output, hidden = self.gru(x)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "# 차원 변화 확인\n",
    "input_size = 100  # 입력 특성 차원\n",
    "hidden_size = 256  # 은닉 상태 차원\n",
    "seq_length = 20   # 시퀀스 길이\n",
    "batch_size = 32   # 배치 크기\n",
    "\n",
    "# 모델 생성\n",
    "model0 = GRU(input_size, hidden_size)\n",
    "model = BiGRU(input_size, hidden_size)\n",
    "\n",
    "# 더미 입력 데이터 생성\n",
    "input_data = torch.randn(batch_size, seq_length, input_size)\n",
    "\n",
    "print(f\"Batch_size: {batch_size}, \\nSequence Length: {seq_length}\")\n",
    "print(f\"Hidden: {hidden_size}\")\n",
    "\n",
    "# Bi-GRU를 통과시켜 representation 추출\n",
    "with torch.no_grad():\n",
    "    output0, hidden0 = model0(input_data)\n",
    "    output, hidden = model(input_data)\n",
    "\n",
    "fbhidden0 = hidden0[-1]  # GRU의 은닉 상태를 합칩니다.\n",
    "fbhidden = torch.cat([hidden[-2], hidden[-1]], dim=-1)  # 양방향 GRU의 은닉 상태를 합칩니다.\n",
    "\n",
    "print()\n",
    "print(\"GRU----------------------\")\n",
    "print(f\"입력 차원: {input_data.shape}\")\n",
    "print(f\"출력 차원: {output0.shape}\")\n",
    "print(f\"은닉 상태 차원: {hidden0.shape}\")\n",
    "print(f\"마지막 은닉 상태 차원: {fbhidden0.shape}\")\n",
    "\n",
    "print()\n",
    "print(\"Bi-GRU-------------------\")\n",
    "print(f\"입력 차원: {input_data.shape}\")\n",
    "print(f\"출력 차원: {output.shape}\")\n",
    "print(f\"은닉 상태 차원: {hidden.shape}\")\n",
    "print(f\"마지막 은닉 상태 차원: {fbhidden.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f64689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n",
      "torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(10, 20)  # 예시로 랜덤 텐서 생성\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "sm = nn.Softmax(dim=1)\n",
    "\n",
    "res = sm(x)\n",
    "\n",
    "print(x.shape)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3e5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
